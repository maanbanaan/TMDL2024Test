{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manue\\AppData\\Local\\Temp\\ipykernel_23100\\2497486820.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "df_after_member = pd.read_csv(r\"data\\newest\\subset_afterT_member.csv\")\n",
    "df_after_nonmember = pd.read_csv(r\"data\\newest\\subset_afterT_nonmember.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5457450"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_after_nonmember)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quantity                 -300.0\n",
       "Rev                     -314.29\n",
       "HL3_101                       0\n",
       "HL3_102                       0\n",
       "HL3_103                       0\n",
       "HL3_104                       0\n",
       "HL3_105                       1\n",
       "HL3_106                       0\n",
       "HL3_107                       0\n",
       "HL3_108                       0\n",
       "HL3_109                       0\n",
       "HL3_110                       0\n",
       "HL3_111                       0\n",
       "HL3_112                       0\n",
       "HL3_114                       0\n",
       "HL3_115                       0\n",
       "HL3_116                       0\n",
       "HL3_117                       0\n",
       "HL3_118                       0\n",
       "HL3_119                       0\n",
       "HL3_120                       0\n",
       "HL3_121                       0\n",
       "HL3_122                       0\n",
       "HL3_123                       0\n",
       "HL3_124                       0\n",
       "HL3_125                       0\n",
       "HL3_126                       0\n",
       "HL3_127                       0\n",
       "HL3_128                       0\n",
       "HL3_129                       0\n",
       "HL3_130                       0\n",
       "HL3_131                       0\n",
       "HL3_132                       0\n",
       "HL3_133                       0\n",
       "HL3_134                       0\n",
       "HL3_135                       0\n",
       "HL3_136                       0\n",
       "HL3_137                       0\n",
       "HL3_138                       0\n",
       "HL3_139                       0\n",
       "Date                 2023-11-10\n",
       "T                             1\n",
       "Store Closed                  0\n",
       "Operation Type                1\n",
       "Hours_06:00-12:00             1\n",
       "Hours_12:00-18:00             0\n",
       "Hours_18:00-00:00             0\n",
       "Weekend_1                     0\n",
       "Zone_3                        0\n",
       "Zone_5                        0\n",
       "Zone_6                        0\n",
       "Zone_7                        0\n",
       "Zone_8                        0\n",
       "Zone_9                        0\n",
       "holiday                       0\n",
       "ramadan                       0\n",
       "Name: 340013, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_after_member.iloc[df_after_member['Quantity'].idxmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Used to train ML models\n",
    "data = df_after_nonmember.drop(['Rev', 'Date', 'T'], axis=1)\n",
    "data['Operation Type'] = data['Operation Type'] - 1         # changing from (1, 2) to binary\n",
    "label = df_after_nonmember.Rev\n",
    "\n",
    "del df_after_member\n",
    "del df_after_nonmember"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(data, label, test_size = 0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size = 0.1, random_state=42)\n",
    "\n",
    "X_test.to_csv(r'data\\newest\\nonmembers_test_X.csv')\n",
    "y_test.to_csv(r'data\\newest\\nonmembers_test_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types needed for XGB\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "evallist = [(dtrain, 'train'), (dval, 'eval')]\n",
    "\n",
    "del X_temp\n",
    "del y_temp\n",
    "del X_train\n",
    "del y_train\n",
    "del X_test\n",
    "del y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:24.61448\teval-rmse:24.10271\n",
      "[1]\ttrain-rmse:18.96197\teval-rmse:18.54330\n",
      "[2]\ttrain-rmse:14.33956\teval-rmse:13.89106\n",
      "[3]\ttrain-rmse:12.79752\teval-rmse:12.40385\n",
      "[4]\ttrain-rmse:12.11716\teval-rmse:11.72977\n",
      "[5]\ttrain-rmse:11.56241\teval-rmse:11.19513\n",
      "[6]\ttrain-rmse:11.40655\teval-rmse:11.04754\n",
      "[7]\ttrain-rmse:11.24410\teval-rmse:10.88120\n",
      "[8]\ttrain-rmse:11.06721\teval-rmse:10.69000\n",
      "[9]\ttrain-rmse:10.98310\teval-rmse:10.60407\n",
      "[10]\ttrain-rmse:10.93486\teval-rmse:10.55864\n",
      "[11]\ttrain-rmse:10.67749\teval-rmse:10.28972\n",
      "[12]\ttrain-rmse:10.57515\teval-rmse:10.18922\n",
      "[13]\ttrain-rmse:10.53480\teval-rmse:10.14805\n",
      "[14]\ttrain-rmse:10.49314\teval-rmse:10.10841\n",
      "[15]\ttrain-rmse:10.40464\teval-rmse:10.02627\n",
      "[16]\ttrain-rmse:10.37574\teval-rmse:9.99700\n",
      "[17]\ttrain-rmse:10.35580\teval-rmse:9.97698\n",
      "[18]\ttrain-rmse:10.27578\teval-rmse:9.93428\n",
      "[19]\ttrain-rmse:10.19701\teval-rmse:9.85251\n",
      "[20]\ttrain-rmse:10.16124\teval-rmse:9.82508\n",
      "[21]\ttrain-rmse:10.12878\teval-rmse:9.79380\n",
      "[22]\ttrain-rmse:10.09190\teval-rmse:9.76153\n",
      "[23]\ttrain-rmse:10.07768\teval-rmse:9.75228\n",
      "[24]\ttrain-rmse:10.01302\teval-rmse:9.72603\n",
      "[25]\ttrain-rmse:9.99847\teval-rmse:9.71194\n",
      "[26]\ttrain-rmse:9.96766\teval-rmse:9.70420\n",
      "[27]\ttrain-rmse:9.95330\teval-rmse:9.69046\n",
      "[28]\ttrain-rmse:9.94093\teval-rmse:9.67785\n",
      "[29]\ttrain-rmse:9.91729\teval-rmse:9.65535\n",
      "[30]\ttrain-rmse:9.86712\teval-rmse:9.60185\n",
      "[31]\ttrain-rmse:9.79389\teval-rmse:9.54640\n",
      "[32]\ttrain-rmse:9.77901\teval-rmse:9.53330\n",
      "[33]\ttrain-rmse:9.75117\teval-rmse:9.50745\n",
      "[34]\ttrain-rmse:9.74607\teval-rmse:9.50472\n",
      "[35]\ttrain-rmse:9.74280\teval-rmse:9.50200\n",
      "[36]\ttrain-rmse:9.73846\teval-rmse:9.49768\n",
      "[37]\ttrain-rmse:9.72608\teval-rmse:9.49196\n",
      "[38]\ttrain-rmse:9.70311\teval-rmse:9.46160\n",
      "[39]\ttrain-rmse:9.67604\teval-rmse:9.43658\n",
      "[40]\ttrain-rmse:9.66200\teval-rmse:9.42330\n",
      "[41]\ttrain-rmse:9.65638\teval-rmse:9.42087\n",
      "[42]\ttrain-rmse:9.64666\teval-rmse:9.40618\n",
      "[43]\ttrain-rmse:9.64307\teval-rmse:9.40243\n",
      "[44]\ttrain-rmse:9.64006\teval-rmse:9.40067\n",
      "[45]\ttrain-rmse:9.60553\teval-rmse:9.36848\n",
      "[46]\ttrain-rmse:9.59201\teval-rmse:9.35527\n",
      "[47]\ttrain-rmse:9.57640\teval-rmse:9.34180\n",
      "[48]\ttrain-rmse:9.54909\teval-rmse:9.31927\n",
      "[49]\ttrain-rmse:9.52972\teval-rmse:9.30252\n",
      "[50]\ttrain-rmse:9.52269\teval-rmse:9.29504\n",
      "[51]\ttrain-rmse:9.50948\teval-rmse:9.28549\n",
      "[52]\ttrain-rmse:9.48907\teval-rmse:9.27202\n",
      "[53]\ttrain-rmse:9.47852\teval-rmse:9.26657\n",
      "[54]\ttrain-rmse:9.45631\teval-rmse:9.24397\n",
      "[55]\ttrain-rmse:9.44318\teval-rmse:9.23651\n",
      "[56]\ttrain-rmse:9.43878\teval-rmse:9.23167\n",
      "[57]\ttrain-rmse:9.42791\teval-rmse:9.22953\n",
      "[58]\ttrain-rmse:9.42102\teval-rmse:9.22722\n",
      "[59]\ttrain-rmse:9.40777\teval-rmse:9.21134\n",
      "[60]\ttrain-rmse:9.40200\teval-rmse:9.20604\n",
      "[61]\ttrain-rmse:9.39813\teval-rmse:9.20361\n",
      "[62]\ttrain-rmse:9.39096\teval-rmse:9.19704\n",
      "[63]\ttrain-rmse:9.38408\teval-rmse:9.18726\n",
      "[64]\ttrain-rmse:9.37679\teval-rmse:9.18133\n",
      "[65]\ttrain-rmse:9.37073\teval-rmse:9.17834\n",
      "[66]\ttrain-rmse:9.35915\teval-rmse:9.16915\n",
      "[67]\ttrain-rmse:9.34754\teval-rmse:9.15708\n",
      "[68]\ttrain-rmse:9.33101\teval-rmse:9.14886\n",
      "[69]\ttrain-rmse:9.32330\teval-rmse:9.14233\n",
      "[70]\ttrain-rmse:9.31806\teval-rmse:9.13475\n",
      "[71]\ttrain-rmse:9.31467\teval-rmse:9.13118\n",
      "[72]\ttrain-rmse:9.30489\teval-rmse:9.12076\n",
      "[73]\ttrain-rmse:9.30082\teval-rmse:9.11640\n",
      "[74]\ttrain-rmse:9.29603\teval-rmse:9.11091\n",
      "[75]\ttrain-rmse:9.29139\teval-rmse:9.10424\n",
      "[76]\ttrain-rmse:9.28917\teval-rmse:9.10274\n",
      "[77]\ttrain-rmse:9.28525\teval-rmse:9.10139\n",
      "[78]\ttrain-rmse:9.27857\teval-rmse:9.09666\n",
      "[79]\ttrain-rmse:9.26992\teval-rmse:9.09005\n",
      "[80]\ttrain-rmse:9.26446\teval-rmse:9.08597\n",
      "[81]\ttrain-rmse:9.25684\teval-rmse:9.07826\n",
      "[82]\ttrain-rmse:9.24732\teval-rmse:9.06522\n",
      "[83]\ttrain-rmse:9.24239\teval-rmse:9.07224\n",
      "[84]\ttrain-rmse:9.23652\teval-rmse:9.06594\n",
      "[85]\ttrain-rmse:9.21440\teval-rmse:9.04293\n",
      "[86]\ttrain-rmse:9.20738\teval-rmse:9.04950\n",
      "[87]\ttrain-rmse:9.20067\teval-rmse:9.05694\n",
      "[88]\ttrain-rmse:9.19864\teval-rmse:9.05523\n",
      "[89]\ttrain-rmse:9.19208\teval-rmse:9.05676\n",
      "[90]\ttrain-rmse:9.18304\teval-rmse:9.05033\n",
      "[91]\ttrain-rmse:9.17872\teval-rmse:9.04757\n",
      "[92]\ttrain-rmse:9.17391\teval-rmse:9.04639\n",
      "[93]\ttrain-rmse:9.16730\teval-rmse:9.04770\n",
      "[94]\ttrain-rmse:9.16312\teval-rmse:9.04619\n",
      "[95]\ttrain-rmse:9.15887\teval-rmse:9.04652\n",
      "[96]\ttrain-rmse:9.15376\teval-rmse:9.04487\n",
      "[97]\ttrain-rmse:9.15151\teval-rmse:9.04310\n",
      "[98]\ttrain-rmse:9.14560\teval-rmse:9.03670\n",
      "[99]\ttrain-rmse:9.14154\teval-rmse:9.03304\n",
      "[100]\ttrain-rmse:9.14005\teval-rmse:9.03212\n",
      "[101]\ttrain-rmse:9.13204\teval-rmse:9.03045\n",
      "[102]\ttrain-rmse:9.12736\teval-rmse:9.02817\n",
      "[103]\ttrain-rmse:9.12373\teval-rmse:9.02647\n",
      "[104]\ttrain-rmse:9.12089\teval-rmse:9.02739\n",
      "[105]\ttrain-rmse:9.11938\teval-rmse:9.02593\n",
      "[106]\ttrain-rmse:9.11752\teval-rmse:9.02461\n",
      "[107]\ttrain-rmse:9.11488\teval-rmse:9.02213\n",
      "[108]\ttrain-rmse:9.11245\teval-rmse:9.01989\n",
      "[109]\ttrain-rmse:9.10959\teval-rmse:9.01743\n",
      "[110]\ttrain-rmse:9.10566\teval-rmse:9.01437\n",
      "[111]\ttrain-rmse:9.10384\teval-rmse:9.01263\n",
      "[112]\ttrain-rmse:9.10123\teval-rmse:9.00975\n",
      "[113]\ttrain-rmse:9.09628\teval-rmse:9.00633\n",
      "[114]\ttrain-rmse:9.09408\teval-rmse:9.00607\n",
      "[115]\ttrain-rmse:9.08998\teval-rmse:9.00232\n",
      "[116]\ttrain-rmse:9.08704\teval-rmse:9.00136\n",
      "[117]\ttrain-rmse:9.07999\teval-rmse:9.00076\n",
      "[118]\ttrain-rmse:9.07610\teval-rmse:8.99312\n",
      "[119]\ttrain-rmse:9.07439\teval-rmse:8.99183\n",
      "[120]\ttrain-rmse:9.07118\teval-rmse:8.98548\n",
      "[121]\ttrain-rmse:9.06963\teval-rmse:8.98376\n",
      "[122]\ttrain-rmse:9.06827\teval-rmse:8.98285\n",
      "[123]\ttrain-rmse:9.06553\teval-rmse:8.98203\n",
      "[124]\ttrain-rmse:9.06350\teval-rmse:8.97939\n",
      "[125]\ttrain-rmse:9.06152\teval-rmse:8.97849\n",
      "[126]\ttrain-rmse:9.05962\teval-rmse:8.97336\n",
      "[127]\ttrain-rmse:9.05840\teval-rmse:8.97405\n",
      "[128]\ttrain-rmse:9.05721\teval-rmse:8.97325\n",
      "[129]\ttrain-rmse:9.05588\teval-rmse:8.97270\n",
      "[130]\ttrain-rmse:9.05240\teval-rmse:8.96954\n",
      "[131]\ttrain-rmse:9.04979\teval-rmse:8.96747\n",
      "[132]\ttrain-rmse:9.04754\teval-rmse:8.96557\n",
      "[133]\ttrain-rmse:9.04689\teval-rmse:8.96517\n",
      "[134]\ttrain-rmse:9.04559\teval-rmse:8.96363\n",
      "[135]\ttrain-rmse:9.04374\teval-rmse:8.96211\n",
      "[136]\ttrain-rmse:9.04228\teval-rmse:8.96088\n",
      "[137]\ttrain-rmse:9.04144\teval-rmse:8.96060\n",
      "[138]\ttrain-rmse:9.04051\teval-rmse:8.95997\n",
      "[139]\ttrain-rmse:9.03639\teval-rmse:8.95888\n",
      "[140]\ttrain-rmse:9.03518\teval-rmse:8.95896\n",
      "[141]\ttrain-rmse:9.03085\teval-rmse:8.95837\n",
      "[142]\ttrain-rmse:9.02501\teval-rmse:8.95901\n",
      "[143]\ttrain-rmse:9.02328\teval-rmse:8.95702\n",
      "[144]\ttrain-rmse:9.02234\teval-rmse:8.95701\n",
      "[145]\ttrain-rmse:9.01969\teval-rmse:8.95424\n",
      "[146]\ttrain-rmse:9.01776\teval-rmse:8.95350\n",
      "[147]\ttrain-rmse:9.01452\teval-rmse:8.94649\n",
      "[148]\ttrain-rmse:9.01241\teval-rmse:8.94634\n",
      "[149]\ttrain-rmse:9.00954\teval-rmse:8.94697\n",
      "[150]\ttrain-rmse:9.00502\teval-rmse:8.94248\n",
      "[151]\ttrain-rmse:9.00351\teval-rmse:8.94094\n",
      "[152]\ttrain-rmse:9.00122\teval-rmse:8.93830\n",
      "[153]\ttrain-rmse:8.99935\teval-rmse:8.93699\n",
      "[154]\ttrain-rmse:8.99817\teval-rmse:8.93539\n",
      "[155]\ttrain-rmse:8.99370\teval-rmse:8.93209\n",
      "[156]\ttrain-rmse:8.98969\teval-rmse:8.93377\n",
      "[157]\ttrain-rmse:8.98724\teval-rmse:8.93604\n",
      "[158]\ttrain-rmse:8.98387\teval-rmse:8.93611\n",
      "[159]\ttrain-rmse:8.98104\teval-rmse:8.93400\n",
      "[160]\ttrain-rmse:8.97982\teval-rmse:8.93237\n",
      "[161]\ttrain-rmse:8.97786\teval-rmse:8.93060\n",
      "[162]\ttrain-rmse:8.97686\teval-rmse:8.93002\n",
      "[163]\ttrain-rmse:8.97614\teval-rmse:8.92975\n",
      "[164]\ttrain-rmse:8.97443\teval-rmse:8.92920\n",
      "[165]\ttrain-rmse:8.97188\teval-rmse:8.92757\n",
      "[166]\ttrain-rmse:8.96660\teval-rmse:8.92844\n",
      "[167]\ttrain-rmse:8.96308\teval-rmse:8.91746\n",
      "[168]\ttrain-rmse:8.96136\teval-rmse:8.91821\n",
      "[169]\ttrain-rmse:8.95083\teval-rmse:8.92085\n",
      "[170]\ttrain-rmse:8.94748\teval-rmse:8.91843\n",
      "[171]\ttrain-rmse:8.94568\teval-rmse:8.91598\n",
      "[172]\ttrain-rmse:8.94484\teval-rmse:8.91561\n",
      "[173]\ttrain-rmse:8.94310\teval-rmse:8.91494\n",
      "[174]\ttrain-rmse:8.93923\teval-rmse:8.91609\n",
      "[175]\ttrain-rmse:8.93713\teval-rmse:8.91512\n",
      "[176]\ttrain-rmse:8.93576\teval-rmse:8.91513\n",
      "[177]\ttrain-rmse:8.93373\teval-rmse:8.91502\n",
      "[178]\ttrain-rmse:8.93127\teval-rmse:8.91374\n",
      "[179]\ttrain-rmse:8.92856\teval-rmse:8.91216\n",
      "[180]\ttrain-rmse:8.92683\teval-rmse:8.91070\n",
      "[181]\ttrain-rmse:8.92447\teval-rmse:8.90820\n",
      "[182]\ttrain-rmse:8.91992\teval-rmse:8.90610\n",
      "[183]\ttrain-rmse:8.91453\teval-rmse:8.90625\n",
      "[184]\ttrain-rmse:8.91298\teval-rmse:8.90560\n",
      "[185]\ttrain-rmse:8.91116\teval-rmse:8.90566\n",
      "[186]\ttrain-rmse:8.91000\teval-rmse:8.90394\n",
      "[187]\ttrain-rmse:8.90861\teval-rmse:8.90466\n",
      "[188]\ttrain-rmse:8.90488\teval-rmse:8.90404\n",
      "[189]\ttrain-rmse:8.90319\teval-rmse:8.90481\n",
      "[190]\ttrain-rmse:8.90186\teval-rmse:8.90395\n",
      "[191]\ttrain-rmse:8.89978\teval-rmse:8.90273\n",
      "[192]\ttrain-rmse:8.89812\teval-rmse:8.89950\n",
      "[193]\ttrain-rmse:8.89727\teval-rmse:8.89938\n",
      "[194]\ttrain-rmse:8.89671\teval-rmse:8.89884\n",
      "[195]\ttrain-rmse:8.89528\teval-rmse:8.89691\n",
      "[196]\ttrain-rmse:8.89399\teval-rmse:8.89619\n",
      "[197]\ttrain-rmse:8.89280\teval-rmse:8.89526\n",
      "[198]\ttrain-rmse:8.89146\teval-rmse:8.89452\n",
      "[199]\ttrain-rmse:8.89074\teval-rmse:8.89462\n",
      "[200]\ttrain-rmse:8.89004\teval-rmse:8.89381\n",
      "[201]\ttrain-rmse:8.88888\teval-rmse:8.89302\n",
      "[202]\ttrain-rmse:8.88787\teval-rmse:8.89206\n",
      "[203]\ttrain-rmse:8.88663\teval-rmse:8.89185\n",
      "[204]\ttrain-rmse:8.88499\teval-rmse:8.89270\n",
      "[205]\ttrain-rmse:8.88369\teval-rmse:8.89435\n",
      "[206]\ttrain-rmse:8.88288\teval-rmse:8.89412\n",
      "[207]\ttrain-rmse:8.87448\teval-rmse:8.89396\n",
      "[208]\ttrain-rmse:8.87222\teval-rmse:8.89354\n",
      "[209]\ttrain-rmse:8.87012\teval-rmse:8.89706\n",
      "[210]\ttrain-rmse:8.86885\teval-rmse:8.89749\n",
      "[211]\ttrain-rmse:8.86724\teval-rmse:8.89939\n",
      "[212]\ttrain-rmse:8.86621\teval-rmse:8.89854\n",
      "[213]\ttrain-rmse:8.86568\teval-rmse:8.89820\n",
      "[214]\ttrain-rmse:8.86342\teval-rmse:8.89996\n",
      "[215]\ttrain-rmse:8.86111\teval-rmse:8.89809\n",
      "[216]\ttrain-rmse:8.86005\teval-rmse:8.89731\n",
      "[217]\ttrain-rmse:8.85850\teval-rmse:8.89709\n",
      "[218]\ttrain-rmse:8.85734\teval-rmse:8.89669\n",
      "[219]\ttrain-rmse:8.85408\teval-rmse:8.89246\n",
      "[220]\ttrain-rmse:8.85308\teval-rmse:8.89129\n",
      "[221]\ttrain-rmse:8.85194\teval-rmse:8.89010\n",
      "[222]\ttrain-rmse:8.85121\teval-rmse:8.89100\n",
      "[223]\ttrain-rmse:8.84893\teval-rmse:8.88950\n",
      "[224]\ttrain-rmse:8.84804\teval-rmse:8.89020\n",
      "[225]\ttrain-rmse:8.84748\teval-rmse:8.89013\n",
      "[226]\ttrain-rmse:8.84678\teval-rmse:8.88868\n",
      "[227]\ttrain-rmse:8.84570\teval-rmse:8.88758\n",
      "[228]\ttrain-rmse:8.84488\teval-rmse:8.88479\n",
      "[229]\ttrain-rmse:8.83868\teval-rmse:8.89097\n",
      "[230]\ttrain-rmse:8.83488\teval-rmse:8.88842\n",
      "[231]\ttrain-rmse:8.83088\teval-rmse:8.89221\n",
      "[232]\ttrain-rmse:8.82977\teval-rmse:8.89266\n",
      "[233]\ttrain-rmse:8.82878\teval-rmse:8.89179\n",
      "[234]\ttrain-rmse:8.82824\teval-rmse:8.89131\n",
      "[235]\ttrain-rmse:8.82554\teval-rmse:8.89781\n",
      "[236]\ttrain-rmse:8.82433\teval-rmse:8.89680\n",
      "[237]\ttrain-rmse:8.82391\teval-rmse:8.89668\n",
      "[238]\ttrain-rmse:8.82238\teval-rmse:8.89493\n",
      "[239]\ttrain-rmse:8.82072\teval-rmse:8.89458\n",
      "[240]\ttrain-rmse:8.81900\teval-rmse:8.89468\n",
      "[241]\ttrain-rmse:8.81780\teval-rmse:8.89328\n",
      "[242]\ttrain-rmse:8.81668\teval-rmse:8.89430\n",
      "[243]\ttrain-rmse:8.81597\teval-rmse:8.89392\n",
      "[244]\ttrain-rmse:8.81278\teval-rmse:8.88978\n",
      "[245]\ttrain-rmse:8.81119\teval-rmse:8.88878\n",
      "[246]\ttrain-rmse:8.80640\teval-rmse:8.89298\n",
      "[247]\ttrain-rmse:8.80537\teval-rmse:8.89304\n",
      "[248]\ttrain-rmse:8.80455\teval-rmse:8.89273\n",
      "[249]\ttrain-rmse:8.80249\teval-rmse:8.89197\n",
      "[250]\ttrain-rmse:8.80196\teval-rmse:8.89172\n",
      "[251]\ttrain-rmse:8.80074\teval-rmse:8.89061\n",
      "[252]\ttrain-rmse:8.79877\teval-rmse:8.89154\n",
      "[253]\ttrain-rmse:8.79777\teval-rmse:8.89193\n",
      "[254]\ttrain-rmse:8.79693\teval-rmse:8.89075\n",
      "[255]\ttrain-rmse:8.79584\teval-rmse:8.89050\n",
      "[256]\ttrain-rmse:8.79491\teval-rmse:8.88948\n",
      "[257]\ttrain-rmse:8.79429\teval-rmse:8.88925\n",
      "[258]\ttrain-rmse:8.79319\teval-rmse:8.88875\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "# TODO: hyper opt\n",
    "param = {'max_depth': 5, 'eta': 0.5, 'objective': 'reg:squarederror', 'colsample_bytree':0.8}\n",
    "\n",
    "num_round = 400\n",
    "bst = xgb.train(param, dtrain, num_round, evals=evallist, early_stopping_rounds=30)\n",
    "bst.save_model(r'models\\newest\\prognostic_model_xgb.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/120 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: name 'dtrain' is not defined\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/120 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dtrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: loss, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m: STATUS_OK}\n\u001b[0;32m     26\u001b[0m trials \u001b[38;5;241m=\u001b[39m Trials()\n\u001b[1;32m---> 27\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m120\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# You can adjust this number depending on how long you're willing to wait\u001b[39;49;00m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# best loss after 40 trials: 6.4433288\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\manue\\Sia Partners Case\\new_env\\Lib\\site-packages\\hyperopt\\fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    537\u001b[0m     fn \u001b[38;5;241m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_trials_fmin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[1;32mc:\\Users\\manue\\Sia Partners Case\\new_env\\Lib\\site-packages\\hyperopt\\base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;66;03m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;66;03m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;66;03m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfmin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[1;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_trials_fmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# -- prevent recursion\u001b[39;49;00m\n\u001b[0;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\manue\\Sia Partners Case\\new_env\\Lib\\site-packages\\hyperopt\\fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\manue\\Sia Partners Case\\new_env\\Lib\\site-packages\\hyperopt\\fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\manue\\Sia Partners Case\\new_env\\Lib\\site-packages\\hyperopt\\fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\manue\\Sia Partners Case\\new_env\\Lib\\site-packages\\hyperopt\\fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[1;32mc:\\Users\\manue\\Sia Partners Case\\new_env\\Lib\\site-packages\\hyperopt\\base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[0;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[0;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[0;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[1;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[0;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[1;32mIn[1], line 16\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjective\u001b[39m(params):\n\u001b[0;32m     14\u001b[0m     cv_results \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mcv(\n\u001b[0;32m     15\u001b[0m         params,\n\u001b[1;32m---> 16\u001b[0m         \u001b[43mdtrain\u001b[49m,\n\u001b[0;32m     17\u001b[0m         num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m,\n\u001b[0;32m     18\u001b[0m         nfold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m     19\u001b[0m         metrics\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m'\u001b[39m},\n\u001b[0;32m     20\u001b[0m         early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     21\u001b[0m         seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     22\u001b[0m     )\n\u001b[0;32m     23\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(cv_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest-rmse-mean\u001b[39m\u001b[38;5;124m'\u001b[39m])  \u001b[38;5;66;03m# Change rmse to your evaluation metric if different\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: loss, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m: STATUS_OK}\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dtrain' is not defined"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, STATUS_OK, fmin, tpe, Trials\n",
    "import xgboost as xgb\n",
    "\n",
    "space = {\n",
    "    'max_depth': hp.choice('max_depth', range(3, 12, 1)),\n",
    "    'eta': hp.uniform('eta', 0.01, 1),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1.0),\n",
    "    'subsample': hp.uniform('subsample', 0.4, 1.0),\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse'  # You can add more metrics relevant to your task\n",
    "}\n",
    "\n",
    "def objective(params):\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=80,\n",
    "        nfold=5,\n",
    "        metrics={'rmse'},\n",
    "        early_stopping_rounds=10,\n",
    "        seed=42\n",
    "    )\n",
    "    loss = min(cv_results['test-rmse-mean'])  # Change rmse to your evaluation metric if different\n",
    "    return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals = 120,  # You can adjust this number depending on how long you're willing to wait\n",
    "    trials=trials\n",
    ")\n",
    "\n",
    "# best loss after 40 trials: 6.4433288\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.40130062957308954,\n",
       " 'eta': 0.04912900986421432,\n",
       " 'max_depth': 2,\n",
       " 'subsample': 0.7055134369878739}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4876719268127706"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.1, random_state=42)\n",
    "\n",
    "del data\n",
    "del label\n",
    "\n",
    "reg = LassoCV(cv=5, random_state=0).fit(X_train, y_train)\n",
    "reg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models\\\\prognostic_model_lasso.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving model\n",
    "from joblib import dump\n",
    "\n",
    "dump(reg, r'models\\prognostic_model_lasso.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: -99.65703139608165\n",
      "max: -3.0157175187344993\n",
      "mean: -19.66147003221858\n"
     ]
    }
   ],
   "source": [
    "prognostic_lasso = reg.predict(X_members)\n",
    "print(f\"min: {min(prognostic_lasso)}\\nmax: {max(prognostic_lasso)}\\nmean: {prognostic_lasso.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE naive predictions: 26.876908670419645\n"
     ]
    }
   ],
   "source": [
    "# Our models do a bit better than just predicting the mean revenue\n",
    "\n",
    "pred_naive = y_train.mean()\n",
    "print(\"RMSE naive predictions:\", np.sqrt(np.mean((pred_naive-y_test)**2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
